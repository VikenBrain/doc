

# 天猫用户重复购买预测



### 评估指标

---

#### `AUC`

(Area Under Curve)
$$
AUC = {\sum_{i \in positive Class}rank_{i} - {M(1 + M) \over 2} \over{ M * N} }
$$
code

```python
import numpy as np
from sklearn.metrics import roc_auc_score

y_true = np.array([0, 0, 1, 1])
y_scores = np.array([0.1, 0.4, 0.35, 0.8])

print(roc_auc_score(y_true, y_scores))
...
>> 0.75
```

解释
两个方面的含义：

1. `AUC`只是反映模型对正负样本排序能力的强弱，对score的大小和精度没有要求；
2. `AUC`越高，模型排序能力越强。理论上，当模型把所有正样本都排在负样本之前时，`AUC`为1.0，是理论的最大值。举例，如果有100个样本，其中20个为正样本，80个负样本。我们通过模型给每个样本打分。如果每个正样本的score/probability都高于所有负样本，则`AUC`为最高值1.0

### 常见数据分布

#### 伯努利分布

概率质量函数
$$
P(X = x) =
\begin{cases}
1 - p, & \text{x = 0}  \\
p, & \text{x = 1}
\end{cases}
$$
伯努利分布只有两种情况，0或者是1。

#### 二项式分布

二项式分布式在n个独立的是/非实验中成功次数的离散概率分布，其中每次试验的成功概率都为p。

概率质量函数
$$
P(X = x) = \frac{n!}{(n - x)!x!}p^xq^{n-x}
$$

#### 泊松分布

#### 正态分布

#### 指数分布



### 特征归一化

特征归一化的目的就是要消除数据特征之间的量纲影响，使不同指标之间具有可比性。

#### 线性函数归一化

实质就是将数据映射到[0, 1]范围内
$$
x_{norm} = \frac{X - X_{min}}{X_{max} - X_{min}}
$$

#### 零均值归一化

(Z-Score Normalization)，将数据映射到均值为0、标准差为1的分布上
$$
z = \frac{x - \mu}{\delta}
$$
<span style="color:red;">备注</span>

<span style="color:yellow;">通过梯度下降求解的模型，归一化会对收敛速度产生影响，因此在通常情况下都需要归一化。这些模型包括线性回归、逻辑回归、支持向量机、神经网络等，但对于决策树模型一般不需要进行归一化处理。</span>

### 类别特征转换

主要是指字符串形式的转换。只有决策树等少数模型能直接处理字符串形式的输入；而逻辑回归、`SVM`等模型必须将类别型特征处理成数值型特征后才能工作。

- 序号编码。高、中、低（3、2、1）转换后依旧保留大小关系
- 独热编码(one-hot)编码
- 二进制编码。不同于热编码的是允许多位为1，二进制编码的本质是利用二进制对ID进行哈希映射，比热编码节省时间。

